{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"en/","title":"Symbiotic Programming Index (SPI)","text":""},{"location":"en/#why-this-project-exists","title":"Why this project exists","text":"<p>The rise of large language models (LLMs) has unsettled one of the core assumptions of computer science: that programming is the act of human authorship, line by line, where logic and intention are painstakingly encoded into formal syntax.</p> <p>Today, AI systems can generate entire modules, pipelines, even complete products. The human role is shifting: from writing code to orchestrating workflows, validating outputs, and safeguarding intent.</p> <p>This transformation demands more than anecdotes or personal workflows. It requires a reproducible, measurable framework to capture the maturity and reliability of human\u2013AI programming.  </p> <p>This is why we created the Symbiotic Programming Index (SPI).</p>"},{"location":"en/#from-vibe-coding-to-spi","title":"From Vibe Coding to SPI","text":"<p>The concept of \u201cvibe coding\u201d emerged as practitioners began to use AI not just as a snippet generator, but as a co-developer capable of sustaining multi-step orchestration.</p> <ul> <li>Humans act at the architectural and judgment level.  </li> <li>AI executes the majority of code generation, explanations, and validation.  </li> <li>The workflow becomes a rhythm: cache prompts, orchestrate multiple agents, validate results, and replay reliably.</li> </ul> <p>But anecdotes are not enough. To move beyond intuition, vibe coding must be formalised. The next step is measurement: defining indices that make human\u2013AI programming visible, testable, and comparable.</p> <p>SPI is that framework.</p>"},{"location":"en/#why-these-five-dimensions","title":"Why these five dimensions?","text":"<p>SPI initially defined four core dimensions to capture the paradigm shift:</p> <ol> <li>Code Quality (Qc) \u2014 Accuracy and completeness of outputs across tests, CI/CD, and architecture.  </li> <li>Human-off Ratio (HoR) \u2014 To what extent can humans \u201clet go\u201d while workflows remain accountable?  </li> <li>AI Explainability (Exp) \u2014 Can AI coders explain their design choices intelligibly and pedagogically?  </li> <li>Stability (Stb) \u2014 Do workflows reproduce across prompts, sessions, and model versions?  </li> <li>Natural Language Engagement (NLE) \u2014 Ensuring orchestration works across languages and cultures, not just English.    Without this, AI programming risks creating new divides in global education and industry.</li> </ol> <p>Together, these five dimensions offer both technical depth and social breadth: from unit tests and reproducibility, to pedagogy, professional identity, and global fairness.</p>"},{"location":"en/#priority-and-progression","title":"Priority and progression","text":"<p>The five dimensions are not flat; they form a research staircase \u2014 from practical foundations to deep societal impact:</p> <ol> <li>Qc (Code Quality) \u2192 the entry point. Without quality, nothing else matters.  </li> <li>HoR (Human-off Ratio) \u2192 once quality is stable, measure how far humans can step back.  </li> <li>Exp (AI Explainability) \u2192 with reduced intervention, demand that AI explains itself in ways humans can trust and learn from.  </li> <li>Stb (Stability) \u2192 the maturity test. Workflows must remain reproducible across runs, contexts, and model versions.  </li> <li>NLE (Natural Language Engagement) \u2192 the highest peak. True symbiosis must work across languages and cultures, avoiding an English-only bottleneck.</li> </ol> <p>In short:</p> <ul> <li>Qc + Stb are the industrial foundation \u2014 making workflows reliable and trustworthy.  </li> <li>HoR + Exp are the academic and philosophical breakthrough \u2014 redefining the engineer\u2019s role and AI\u2019s epistemic value.  </li> <li>NLE is the societal horizon \u2014 ensuring global fairness and inclusivity in AI programming.  </li> </ul> <p>This priority structure also reflects analysis difficulty and depth: from QC (low difficulty, mid depth) \u2192 HoR (moderate) \u2192 Exp (higher) \u2192 Stb (very high) \u2192 NLE (extreme). The first three are \u201cvisible mountains,\u201d while Stb and NLE are \u201cpeaks in the clouds.\u201d</p>"},{"location":"en/#spi-formula-with-nle","title":"\ud83d\udcd0 SPI Formula (with NLE)","text":"<p>We define the Symbiotic Programming Index (SPI) as a weighted combination of five dimensions:</p> <p>$$ SPI = w_{Qc}\\,Qc \\;+\\; w_{HoR}\\,HoR \\;+\\; w_{Exp}\\,Exp \\;+\\; w_{Stb}\\,Stb \\;+\\; w_{NLE}\\,NLE, \\quad \\text{s.t. } \\sum w_i = 1,\\; w_i \\ge 0 $$</p> <p>Where:</p> <ul> <li>$Qc$ \u2014 Code Quality: accuracy, completeness, maintainability  </li> <li>$HoR$ \u2014 Human-off Ratio: extent to which humans can \u201clet go\u201d while workflows remain accountable  </li> <li>$Exp$ \u2014 Explainability: clarity and pedagogical value of AI\u2019s self-explanations  </li> <li>$Stb$ \u2014 Stability: reproducibility across runs, sessions, and model versions  </li> <li>$NLE$ \u2014 Natural Language Engagement: the effect of language, wording, or cross-lingual variation on quality and explainability  </li> </ul> <p>The weights ($w_i$) are adjustable depending on context: - Industrial settings may emphasise $Qc$ and $Stb$ - Education may emphasise $Exp$ and $HoR$ - Global fairness highlights $NLE$  </p>"},{"location":"en/#what-this-documentation-provides","title":"What this documentation provides","text":"<p>This repository is structured to provide both narrative and methodology:</p> <ul> <li>Drafts and Licenses</li> <li>v0.1 Draft \u2014 snapshot of the original proposal</li> <li> <p>License \u2014 sharing and citation rules</p> </li> <li> <p>Dimensions</p> </li> <li>Code Quality (Qc)</li> <li>Human-off Ratio (HoR)</li> <li>AI Explainability (Exp)</li> <li>Stability (Stb)</li> <li> <p>Natural Language Engagement (NLE)</p> </li> <li> <p>Datasets</p> </li> <li>Overview \u2014 types of logs and traces</li> <li>Schema \u2014 data model</li> <li> <p>Governance \u2014 ethics and de-identification</p> </li> <li> <p>Experiments</p> </li> <li>Protocols \u2014 reproducible designs</li> <li>Results \u2014 summaries and snapshots</li> </ul>"},{"location":"en/#quick-navigation","title":"Quick navigation","text":"<ul> <li>Getting started \u2192 Begin with the v0.1 Draft </li> <li>Research details \u2192 Dive into Methodology and other dimension folders  </li> <li>Community use \u2192 Cite SPI, contribute references, or use datasets under the License</li> </ul>"},{"location":"en/#enduring-aim","title":"Enduring aim","text":"<p>SPI is not about faster coding. It is about rethinking the nature of programming itself:  </p> <ul> <li>From authorship to orchestration  </li> <li>From snippets to workflows  </li> <li>From isolated benchmarks to reproducible indices  </li> </ul> <p>Our aim is to build a visible, teachable, and reproducible foundation for software engineering in the era of AI \u2014 a framework that can be tested, taught, and trusted.</p>"},{"location":"en/license/","title":"License","text":"<ul> <li>Code &amp; software: Apache 2.0 (see <code>LICENSE</code>)  </li> <li>Docs &amp; research materials: CC BY-NC 4.0 (see <code>LICENSE-docs.md</code>)</li> </ul>"},{"location":"en/exp/methodology/","title":"Methodology","text":"<p>Framing: Turn philosophy (authorship, agency, accountability) into operational metrics.</p> <p>Hypotheses (abridged): 1) Productivity requires Stb without sacrificing Qc 2) Human role shifts to orchestration (\u2191HoR) if Qc/Stb hold and Exp is intelligible 3) Hybrid QA (AI checks + human oversight) outperforms extremes 4) Languages evolve into orchestration DSLs when Exp/Stb are strong</p> <p>Protocols: - Controlled tasks across 3 modes: human-only, AI-only, orchestrated - Logging: prompts, outputs, diffs, tests, interventions - Validity: convergent metrics (defects, time), test\u2013retest reliability, cross-model generalization</p>"},{"location":"en/hor/methodology/","title":"Methodology","text":"<p>Framing: Turn philosophy (authorship, agency, accountability) into operational metrics.</p> <p>Hypotheses (abridged): 1) Productivity requires Stb without sacrificing Qc 2) Human role shifts to orchestration (\u2191HoR) if Qc/Stb hold and Exp is intelligible 3) Hybrid QA (AI checks + human oversight) outperforms extremes 4) Languages evolve into orchestration DSLs when Exp/Stb are strong</p> <p>Protocols: - Controlled tasks across 3 modes: human-only, AI-only, orchestrated - Logging: prompts, outputs, diffs, tests, interventions - Validity: convergent metrics (defects, time), test\u2013retest reliability, cross-model generalization</p>"},{"location":"en/nle/methodology/","title":"Methodology","text":"<p>Framing: Turn philosophy (authorship, agency, accountability) into operational metrics.</p> <p>Hypotheses (abridged): 1) Productivity requires Stb without sacrificing Qc 2) Human role shifts to orchestration (\u2191HoR) if Qc/Stb hold and Exp is intelligible 3) Hybrid QA (AI checks + human oversight) outperforms extremes 4) Languages evolve into orchestration DSLs when Exp/Stb are strong</p> <p>Protocols: - Controlled tasks across 3 modes: human-only, AI-only, orchestrated - Logging: prompts, outputs, diffs, tests, interventions - Validity: convergent metrics (defects, time), test\u2013retest reliability, cross-model generalization</p>"},{"location":"en/qc/methodology/","title":"Methodology","text":"<p>Framing: Turn philosophy (authorship, agency, accountability) into operational metrics.</p> <p>Hypotheses (abridged): 1) Productivity requires Stb without sacrificing Qc 2) Human role shifts to orchestration (\u2191HoR) if Qc/Stb hold and Exp is intelligible 3) Hybrid QA (AI checks + human oversight) outperforms extremes 4) Languages evolve into orchestration DSLs when Exp/Stb are strong</p> <p>Protocols: - Controlled tasks across 3 modes: human-only, AI-only, orchestrated - Logging: prompts, outputs, diffs, tests, interventions - Validity: convergent metrics (defects, time), test\u2013retest reliability, cross-model generalization</p>"},{"location":"en/stb/methodology/","title":"Methodology","text":"<p>Framing: Turn philosophy (authorship, agency, accountability) into operational metrics.</p> <p>Hypotheses (abridged): 1) Productivity requires Stb without sacrificing Qc 2) Human role shifts to orchestration (\u2191HoR) if Qc/Stb hold and Exp is intelligible 3) Hybrid QA (AI checks + human oversight) outperforms extremes 4) Languages evolve into orchestration DSLs when Exp/Stb are strong</p> <p>Protocols: - Controlled tasks across 3 modes: human-only, AI-only, orchestrated - Logging: prompts, outputs, diffs, tests, interventions - Validity: convergent metrics (defects, time), test\u2013retest reliability, cross-model generalization</p>"}]}