# Symbiotic Programming Index (SPI)

---

## ğŸŒ Background & Motivation

Conventional benchmarks such as **CodeXGLUE**, **HumanEval**, and **MBPP** measure the *capabilities of models in isolation*.  
They ask: *Can a model generate correct solutions for given tasks?*

But this is no longer the central question.  
The real challenge is: **How do humans and AI co-produce software reliably, reproducibly, and pedagogically?**

- Traditional metrics ignore **workflow quality** (replay stability, orchestration cost, reproducibility).  
- They ignore **human-off ratio** (how far humans can â€œlet goâ€ without loss of accountability).  
- They ignore **AI explainability** (can AI articulate its reasoning as a tutor, not just a coder).  

**SPI** addresses these blind spots by shifting the unit of analysis:  
ğŸ‘‰ from *models* to *workflows*.  
ğŸ‘‰ from *outputs* to *orchestration*.  
ğŸ‘‰ from *performance* to *symbiosis*.

---

## ğŸ”¬ Methodological Frame

SPI is operationalised through **five measurable dimensions**: Qc, HoR, Exp, Stb, and NLE.  

We study them across **controlled workflows**:

- **Human-only coding** â€” traditional baseline.  
- **AI-only generation** â€” single-shot, minimal orchestration.  
- **Humanâ€“AI orchestration** â€” cached prompts, validators, multi-agent flows.  

**Metrics & Validation:**

- *Qc*: unit/integration pass rates, CI/CD deploy success, static analysis.  
- *HoR*: number of edits, prompt ratio, human LOC %.  
- *Exp*: reviewer-rated clarity, learning outcomes in student studies.  
- *Stb*: testâ€“retest reproducibility, regression recurrence.  
- *NLE*: cross-lingual robustness, semantic drift under translation.  

Validation strategies include:  
- **Convergent validity** â€” SPI vs. defect density / productivity.  
- **Testâ€“retest reliability** â€” same orchestration across model versions.  
- **Cross-model generalisation** â€” GPT, Claude, DeepSeek, Gemini.  

---

## ğŸ¯ Contribution Highlights

- **Academic** â€” A reproducible taxonomy of orchestration workflows and failure modes.  
- **Industrial** â€” Criteria for hybrid QA pipelines, measuring when AI coders can be trusted.  
- **Educational** â€” Pedagogical modules where AI acts as tutor; orchestration as a core competency.  
- **Philosophical** â€” Embedding debates on authorship, agency, and epistemology into measurable indices.  

---


## ğŸ“Š Priority and Progression

The five SPI dimensions do not carry equal weight at all times.  
They form a **research staircase** â€” from practical foundations to higher-order challenges:

1. **Qc (Code Quality)** â†’ the entry point. Without quality, nothing else matters.  
2. **HoR (Human-off Ratio)** â†’ once quality is reliable, measure how far humans can step back.  
3. **Exp (Explainability)** â†’ with reduced human intervention, demand that AI explains itself intelligibly.  
4. **Stb (Stability)** â†’ the maturity test: workflows must remain reproducible across runs, contexts, and model versions.  
5. **NLE (Natural Language Engagement)** â†’ the societal horizon: true symbiosis must work across languages and cultures.

**Grouping:**
- **Qc + Stb** â†’ the **industrial foundation**, ensuring reliability and trustworthiness.  
- **HoR + Exp** â†’ the **academic and philosophical breakthrough**, redefining the role of engineers and AIâ€™s epistemic value.  
- **NLE** â†’ the **societal horizon**, preventing an English-only bottleneck and enabling global inclusivity.  

This priority ordering also mirrors **analysis difficulty and depth**:  
from **Qc (low difficulty, mid depth)** â†’ **HoR (moderate)** â†’ **Exp (high)** â†’ **Stb (very high)** â†’ **NLE (extreme)**.  
The first three are â€œvisible mountains,â€ while Stb and NLE remain â€œpeaks in the clouds.â€

---

## ğŸ“ SPI Formula

$$
\text{SPI}=\; w_{Qc}\,Qc + w_{HoR}\,HoR + w_{Exp}\,Exp + w_{Stb}\,Stb + w_{NLE}\,NLE,\quad
\text{s.t. } \sum_i w_i = 1,\; w_i \ge 0
$$

Weights $w_i$ adapt to context:
- Industry â†’ emphasise $Qc$ + $Stb$
- Education â†’ emphasise $HoR$ + $Exp$
- Global fairness â†’ emphasise $NLE$


---

## ğŸ“š Documentation Structure

- **Dimensions**
  - [Code Quality (Qc)](./qc/index.md)  
  - [Human-off Ratio (HoR)](./hor/index.md)  
  - [AI Explainability (Exp)](./exp/index.md)  
  - [Stability (Stb)](./stb/index.md)  
  - [Natural Language Engagement (NLE)](./nle/index.md)  

- **Licenses**
  - [License](./license.md) â€” sharing and citation rules

---

## ğŸš€ Enduring Aim

SPI is not just about *faster coding*.  
It is about **redefining the act of programming itself**:  

- From authorship to orchestration.  
- From isolated benchmarks to reproducible indices.  
- From intuition to science.  

Our aim is to establish a **visible, teachable, and reproducible foundation** for software engineering in the AI era.  
